{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda9c034",
   "metadata": {},
   "source": [
    "# Build an ML Pipeline for Airfoil noise prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cb2df",
   "metadata": {},
   "source": [
    "**Airfoil**: A cross-sectional shape of a wing, blade, or sail that is designed to generate lift when air flows over it. In aeronautics, airfoils are critical components in aircraft wings, helicopter rotors, propellers, and turbine blades. The shape of an airfoil directly affects its aerodynamic performance, including lift generation, drag characteristics, and importantly, the noise it produces as air flows over its surface. Understanding and predicting airfoil noise is essential for designing quieter, more efficient aircraft and reducing environmental noise pollution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635f4a2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78a29a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/maishuji/Workplace/ibm-data-engineer/machine-learning-pipeline-for-airfoil-noise-prediction/.venv/lib/python3.13/site-packages (4.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /home/maishuji/Workplace/ibm-data-engineer/machine-learning-pipeline-for-airfoil-noise-prediction/.venv/lib/python3.13/site-packages (from pyspark) (0.10.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: findspark in /home/maishuji/Workplace/ibm-data-engineer/machine-learning-pipeline-for-airfoil-noise-prediction/.venv/lib/python3.13/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.5-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.3.5-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark\n",
    "%pip install findspark\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280edb9",
   "metadata": {},
   "source": [
    "## Part 1 - Perform ETL activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ee674",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c550f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced3326",
   "metadata": {},
   "source": [
    "### Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a360792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/14 11:16:47 WARN Utils: Your hostname, maishuji, resolves to a loopback address: 127.0.1.1; using 192.168.0.18 instead (on interface wlp4s0)\n",
      "25/12/14 11:16:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/14 11:16:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Airfoil Noise Prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ef81f",
   "metadata": {},
   "source": [
    "### Load the csv file into a datadrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325ce99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-14 11:19:12--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 60682 (59K) [text/csv]\n",
      "Saving to: ‘./../data/raw/NASA_airfoil_noise_raw.csv’\n",
      "\n",
      "./../data/raw/NASA_ 100%[===================>]  59.26K   384KB/s    in 0.2s    \n",
      "\n",
      "2025-12-14 11:19:13 (384 KB/s) - ‘./../data/raw/NASA_airfoil_noise_raw.csv’ saved [60682/60682]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv -O ./../data/raw/NASA_airfoil_noise_raw.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b16f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./../data/raw/NASA_airfoil_noise_raw.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4b6b4",
   "metadata": {},
   "source": [
    "### Print top 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2394d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761aec07",
   "metadata": {},
   "source": [
    "### Print the total number of rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3308a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count before removing duplicates and nulls: 1522\n"
     ]
    }
   ],
   "source": [
    "rowcount1 = df.count()\n",
    "print(f\"Row count before removing duplicates and nulls: {rowcount1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8b338",
   "metadata": {},
   "source": [
    "### Drop all the duplicate rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb5d4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b72f5",
   "metadata": {},
   "source": [
    "### Print the total number of rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eda21a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after removing duplicates: 1503\n"
     ]
    }
   ],
   "source": [
    "rowcount2 = df.count()\n",
    "print(f\"Row count after removing duplicates: {rowcount2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454848d",
   "metadata": {},
   "source": [
    "### Drop all the rows that contain null values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "351a32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705714cb",
   "metadata": {},
   "source": [
    "### Print the total number of rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66e0a9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after removing nulls: 1499\n"
     ]
    }
   ],
   "source": [
    "rowcount3 = df.count()\n",
    "print(f\"Row count after removing nulls: {rowcount3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e4b03",
   "metadata": {},
   "source": [
    "### Rename the column \"SoundLevel\" to \"SoundLevelDecibels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d653b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"SoundLevel\", \"SoundLevelDecibels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed1ead",
   "metadata": {},
   "source": [
    "### Save the dataframe in parquet format, name the file as \"NASA_airfoil_noise_cleaned.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54214677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"./../data/processed/NASA_airfoil_noise_cleaned.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0af06a",
   "metadata": {},
   "source": [
    "### Part 1 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "219dc316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 - Evaluation\n",
      "Total rows =  1522\n",
      "Total rows after dropping duplicate rows =  1503\n",
      "Total rows after dropping duplicate rows and rows with null values =  1499\n",
      "New column name =  SoundLevelDecibels\n",
      "NASA_airfoil_noise_cleaned.parquet exists : True\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 - Evaluation\")\n",
    "\n",
    "print(\"Total rows = \", rowcount1)\n",
    "print(\"Total rows after dropping duplicate rows = \", rowcount2)\n",
    "print(\"Total rows after dropping duplicate rows and rows with null values = \", rowcount3)\n",
    "print(\"New column name = \", df.columns[-1])\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"NASA_airfoil_noise_cleaned.parquet exists :\", os.path.isdir(\"./../data/processed/NASA_airfoil_noise_cleaned.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8f208",
   "metadata": {},
   "source": [
    "## Part 2 - Create a Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe828e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d0ce1",
   "metadata": {},
   "source": [
    "### Load data from the .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62f29ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+------------------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+\n",
      "|      400|          0.0|     0.3048|              31.7|             0.00331266|           125.045|\n",
      "|    16000|          1.5|     0.3048|              71.3|             0.00336729|           106.582|\n",
      "|      630|          3.0|     0.3048|              55.5|             0.00452492|           129.569|\n",
      "|      315|          4.0|     0.2286|              31.7|             0.00509068|           123.609|\n",
      "|      630|          4.0|     0.2286|              31.7|             0.00509068|           130.349|\n",
      "+---------+-------------+-----------+------------------+-----------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"./../data/processed/NASA_airfoil_noise_cleaned.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bb775",
   "metadata": {},
   "source": [
    "### Print the total number of rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a5d421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after reading the cleaned parquet file: 1499\n"
     ]
    }
   ],
   "source": [
    "rowcount4 = df.count()\n",
    "print(f\"Row count after reading the cleaned parquet file: {rowcount4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16380688",
   "metadata": {},
   "source": [
    "### Define the VectorAssembler pipeline stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38c317",
   "metadata": {},
   "source": [
    "Using all the columns except the last one (\"SoundLevelDecibels\") and assemble it into a single column \"features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa0a57b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assembler = VectorAssembler(inputCols=df.columns[:-1], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b1800",
   "metadata": {},
   "source": [
    "### Define the StandardScaler pipeline stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25a27951",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82dfda",
   "metadata": {},
   "source": [
    "### Define the Model creation pipeline stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a68905f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"SoundLevelDecibels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e36b2",
   "metadata": {},
   "source": [
    "### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2781c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff89a6f",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ac0989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3311209",
   "metadata": {},
   "source": [
    "### Fit the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6efc33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/14 12:23:32 WARN Instrumentation: [6b535e65] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1a959",
   "metadata": {},
   "source": [
    "### Part 2 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f2072e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 - Evaluation\n",
      "Total rows =  1499\n",
      "Pipeline Stage 1 =  VectorAssembler\n",
      "Pipeline Stage 2 =  StandardScaler\n",
      "Pipeline Stage 3 =  LinearRegression\n",
      "Label column =  SoundLevelDecibels\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 2 - Evaluation\")\n",
    "print(\"Total rows = \", rowcount4)\n",
    "ps = [str(x).split(\"_\")[0] for x in pipeline.getStages()]\n",
    "\n",
    "print(\"Pipeline Stage 1 = \", ps[0])\n",
    "print(\"Pipeline Stage 2 = \", ps[1])\n",
    "print(\"Pipeline Stage 3 = \", ps[2])\n",
    "\n",
    "print(\"Label column = \", lr.getLabelCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519eda3",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluatiion of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe135a22",
   "metadata": {},
   "source": [
    "### Predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "915bd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipelineModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e000957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|SoundLevelDecibels|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|[200.0,7.3,0.2286...|           128.679|122.59722914376778|\n",
      "|[200.0,8.9,0.1016...|            133.42|127.37968204568838|\n",
      "|[200.0,9.5,0.0254...|           119.146|130.34077425074506|\n",
      "|[200.0,9.5,0.0254...|           116.074|131.11016975113537|\n",
      "|[200.0,9.9,0.1524...|           134.319|127.12627360125096|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\", \"SoundLevelDecibels\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991d351",
   "metadata": {},
   "source": [
    "### Print the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f005cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data =  24.99766625502418\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE) on test data = \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98687db7",
   "metadata": {},
   "source": [
    "### Print the MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c81ae054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on test data =  3.9136790958812044\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f4050",
   "metadata": {},
   "source": [
    "### Print the R-Squared (R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26ded5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data =  0.4959688408974623\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared (R2) on test data = \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c9e29",
   "metadata": {},
   "source": [
    "### Part 3 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4902241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - Evaluation\n",
      "Mean Squared Error =  25.0\n",
      "Mean Absolute Error =  3.91\n",
      "R Squared =  0.5\n",
      "Intercept =  132.88\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 3 - Evaluation\")\n",
    "\n",
    "print(\"Mean Squared Error = \", round(mse,2))\n",
    "print(\"Mean Absolute Error = \", round(mae,2))\n",
    "print(\"R Squared = \", round(r2,2))\n",
    "\n",
    "lrModel = pipelineModel.stages[-1]\n",
    "\n",
    "print(\"Intercept = \", round(lrModel.intercept,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
